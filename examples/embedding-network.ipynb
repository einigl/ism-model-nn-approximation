{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks and modules assembly\n",
    "\n",
    "The `EmbeddingNetwork` module is a torch `Module` that permit to easily add torch modules before or after a neural network. It can be useful to customize a neural network from a classic architecture like `FullyConnected`. It can also be used to mimic the use `Operator` with torch functions, for instance if we want to differentiate a network with respect to the inputs variables rather than normalized variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(\"\"), \"..\"))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "from nnbma.layers import AdditionalModule, AdditionalModuleFromExisting\n",
    "from nnbma.networks import FullyConnected, EmbeddingNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `AdditionalModule` module\n",
    "\n",
    "An `AdditionalModule` is basically a torch `Module`. The advantage of these modules is to ensure upstream compatibility of input and output dimensions.\n",
    "\n",
    "In addition to the Module class, they have two attributes `input_features` and `output_features`. As these modules are compatible with the use of batches, these values correspond to the last dimension of the tensors.\n",
    "\n",
    "Here's an example of a module that takes tensors of size 2 as arguments and returns tensors of size 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul(AdditionalModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(3, 2)\n",
    "        self.W = torch.normal(0, 1, size=(3, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.W)\n",
    "\n",
    "\n",
    "matmul = MatMul()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to create a module that takes a tensor of arbitrary size as input and return also a tensor of arbitrary size.\n",
    "\n",
    "__Note:__ In this case, we show an alternative to the implementation based on `AdditionalModule`, using this time `AdditionalModuleFromExisting`. This class is useful when the additional module is directly based on an existing Torch function or Module as we don't need to override the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = AdditionalModuleFromExisting(None, None, torch.exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you may want to create a module that takes as input a tensor of arbitrary size and returns a tensor of fixed size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Moments(AdditionalModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(None, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        m1 = torch.mean(x, axis=-1, keepdim=True)\n",
    "        m2 = torch.mean((x - m1) ** 2, axis=-1, keepdim=True)\n",
    "        return torch.concatenate((m1, m2), axis=-1)\n",
    "\n",
    "\n",
    "moments = Moments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `EmbeddingNetwork` example\n",
    "\n",
    "The `EmbeddingNetwork` module allows to chain several `AdditionalModule` instances before and/or after an instance of `NeuralNetwork`. The only limitation is the compatibility of the number of input and output features between two consecutive modules.\n",
    "\n",
    "- If a module has a fixed number of output features `output_features`, the next module must have an `input_features` attribute which is identical.\n",
    "- If a module has an arbitrary number of output features (`output_features = None`), the next module must also have an arbitrary number of input features (`input_features = None`). __Note:__ the inverse is not true, a module with a fixed number of output is compatible with a module with an arbitrary number of input.\n",
    "\n",
    "We assume that we have the following `NeuralNetwork` which compute 20 outputs from 2 inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 20\n"
     ]
    }
   ],
   "source": [
    "subnet = FullyConnected(\n",
    "    [2, 10, 10, 20],\n",
    "    nn.ReLU(),\n",
    ")\n",
    "print(subnet.input_features, subnet.output_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use it as a base to build a larger model making the following operation:\n",
    "- Multiplication by a 3x2 matrix to map 3 inputs into 2 outputs\n",
    "- Processing by the fully connected neural network\n",
    "- Application of the exponential function\n",
    "- Computation of th mean and the variance of the different features\n",
    "\n",
    "__Note:__ This architecture has only been created to set an example, and it seems unlikely that it will be of any practical use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[MatMul()]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[AdditionalModuleFromExisting(), Moments()]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = EmbeddingNetwork(subnet, preprocessing=[matmul], postprocessing=[exp, moments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98087585, 0.07246768],\n",
       "       [0.9779798 , 0.06297462],\n",
       "       [0.9804139 , 0.05586525],\n",
       "       [0.9834059 , 0.04427576],\n",
       "       [0.9792155 , 0.03643883],\n",
       "       [0.9786695 , 0.04505088],\n",
       "       [0.9833721 , 0.04092345],\n",
       "       [0.9824467 , 0.05052687],\n",
       "       [0.98621017, 0.0392889 ],\n",
       "       [1.0015066 , 0.04561822]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.normal(0, 1, size=(10, 3)).astype(\"float32\")\n",
    "\n",
    "net(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
