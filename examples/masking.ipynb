{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network training with masked unreliable labels\n",
    "\n",
    "This example presents the procedure to train a model with a loss function that ignores labels that have been identified as unreliable. These labels are said to be masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(\"\"), \"..\"))\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "from nnbma.networks import FullyConnected\n",
    "from nnbma.dataset import RegressionDataset, MaskDataset\n",
    "from nnbma.learning import (\n",
    "    learning_procedure,\n",
    "    LearningParameters,\n",
    "    MaskedMSELoss,\n",
    "    CauchyLoss,\n",
    ")\n",
    "\n",
    "from functions import Fexample as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical function\n",
    "\n",
    "In the following cell, we load and instantiate a vectorial function $f$ implemented as a PyTorch `Module`. For more details on the implementation, see `functions.py`. You can implement your own by following the model.\n",
    "\n",
    "The function is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$$\\left(\\begin{array}{c} t_1\\\\ t_2 \\end{array}\\right) \\longmapsto \\left(\\begin{array}{c} t_1+2t_2\\\\ t_1^2\\\\ t_1t_2^2 \\end{array}\\right)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = F()\n",
    "md(F.latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_sizes = [f.n_inputs, 50, 50, f.n_outputs]  # Can be modified\n",
    "activation = nn.ELU()\n",
    "\n",
    "net = FullyConnected(layers_sizes, activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10_000\n",
    "test_frac = 0.20\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.normal(0, 1, size=(n_samples, F.n_inputs)).astype(\"float32\")\n",
    "Y = f(X)\n",
    "\n",
    "X_train, X_test = X[round(test_frac * n_samples) :], X[: round(test_frac * n_samples)]\n",
    "Y_train_true, Y_test_true = (\n",
    "    Y[round(test_frac * n_samples) :],\n",
    "    Y[: round(test_frac * n_samples)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damage to certain labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_damage = 0.05  # 5%, can be modified\n",
    "\n",
    "# Select a fraction p_damage of the labels\n",
    "mask_train = np.random.rand(*Y_train_true.shape) < p_damage\n",
    "mask_test = np.random.rand(*Y_test_true.shape) < p_damage\n",
    "\n",
    "# Add an error of 1 to 5 to a fraction p_damage of the labels\n",
    "Y_train = np.where(mask_train, Y_train_true + np.random.randint(5) + 1, Y_train_true)\n",
    "Y_test = np.where(mask_test, Y_test_true + np.random.randint(5) + 1, Y_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RegressionDataset(X_train, Y_train)\n",
    "test_dataset = RegressionDataset(X_test, Y_test)\n",
    "\n",
    "train_mask_dataset = MaskDataset(~mask_train)  # Mask is inverted for training\n",
    "test_mask_dataset = MaskDataset(~mask_test)  # Mask is inverted for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a network with masked labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs\n",
    "epochs = 100\n",
    "\n",
    "# Batch size\n",
    "batch_size = 100\n",
    "\n",
    "# Loss function (for non-masked training)\n",
    "loss_no_mask = nn.MSELoss()\n",
    "\n",
    "# Loss function (for masked training)\n",
    "loss_mask = MaskedMSELoss()\n",
    "\n",
    "# Copies of network in order to perform two different trainings\n",
    "net_no_mask = net.copy()\n",
    "net_mask = net.copy()\n",
    "\n",
    "# Optimizers (for both trainings)\n",
    "learning_rate = 1e-3\n",
    "optimizer_no_mask = optim.Adam(net.parameters(), learning_rate)\n",
    "optimizer_mask = optim.Adam(net_mask.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initiated\n",
      "FullyConnected:\n",
      "\tlayers_sizes: [2, 50, 50, 3]\n",
      "\tactivation: ELU(alpha=1.0)\n",
      "\tbatch_norm: False\n",
      "\tinputs_names: None\n",
      "\toutputs_names: None\n",
      "\tinputs_transformer: None\n",
      "\toutputs_transformer: None\n",
      "\tdevice: cpu\n",
      "\tlast_restrictable: True\n",
      ": 2,853 learnable parameters (11.41 kB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 100/100 [00:33<00:00,  2.96it/s, train loss=5.05, val loss=4.3, train error=42460711343034990592.00%, val error=27791656125898686464.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_params = LearningParameters(\n",
    "    loss_no_mask, epochs, batch_size, optimizer_no_mask\n",
    ")\n",
    "\n",
    "results = learning_procedure(\n",
    "    net_no_mask,\n",
    "    (train_dataset, test_dataset),\n",
    "    learning_params,\n",
    "    val_frac=test_frac,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Compute outputs for both training and testing sets\n",
    "Y_train_hat = net_no_mask(X_train)\n",
    "Y_test_hat = net_no_mask(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initiated\n",
      "FullyConnected:\n",
      "\tlayers_sizes: [2, 50, 50, 3]\n",
      "\tactivation: ELU(alpha=1.0)\n",
      "\tbatch_norm: False\n",
      "\tinputs_names: None\n",
      "\toutputs_names: None\n",
      "\tinputs_transformer: None\n",
      "\toutputs_transformer: None\n",
      "\tdevice: cpu\n",
      "\tlast_restrictable: True\n",
      ": 2,853 learnable parameters (11.41 kB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 100/100 [00:41<00:00,  2.39it/s, train loss=0.000929, val loss=0.0027, train error=9.60%, val error=48.31%]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_params = LearningParameters(loss_mask, epochs, batch_size, optimizer_mask)\n",
    "\n",
    "results = learning_procedure(\n",
    "    net_mask,\n",
    "    (train_dataset, test_dataset),\n",
    "    learning_params,\n",
    "    mask_dataset=(train_mask_dataset, test_mask_dataset),\n",
    "    val_frac=test_frac,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Compute outputs for both training and testing sets\n",
    "Y_train_hat_mask = net_mask(X_train)\n",
    "Y_test_hat_mask = net_mask(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between labels estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_hat: np.ndarray, y: np.ndarray, reduce: bool = True):\n",
    "    if reduce:\n",
    "        return np.mean((y_hat - y) ** 2)\n",
    "    return (y_hat - y) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of true, corrupted, estimated without masking and estimated with masking labels\n",
      "True: -1.78, corrup: +3.22, estim. w/o masking: +0.29, estim. with masking: -1.79\n",
      "True: -0.01, corrup: +4.99, estim. w/o masking: -0.20, estim. with masking: +0.02\n",
      "True: +3.58, corrup: +8.58, estim. w/o masking: +0.36, estim. with masking: +3.57\n",
      "True: +2.70, corrup: +7.70, estim. w/o masking: +0.21, estim. with masking: +2.71\n",
      "True: +0.71, corrup: +5.71, estim. w/o masking: -0.13, estim. with masking: +0.73\n",
      "True: +0.53, corrup: +5.53, estim. w/o masking: -0.43, estim. with masking: +0.57\n",
      "True: +2.30, corrup: +7.30, estim. w/o masking: +0.39, estim. with masking: +2.32\n",
      "True: +1.05, corrup: +6.05, estim. w/o masking: +0.45, estim. with masking: +1.05\n",
      "True: -1.22, corrup: +3.78, estim. w/o masking: +0.20, estim. with masking: -1.21\n",
      "True: +2.94, corrup: +7.94, estim. w/o masking: +0.42, estim. with masking: +2.95\n",
      "\n",
      "Average quadratic error between true label and estimated labels\n",
      "Estimated w/o masking vs. true: 3.45e+00\n",
      "Estimated with masking vs. true: 8.15e-04\n",
      "\n",
      "Average quadratic error over all labels (corrupted or not)\n",
      "Estimated w/o masking vs. true: 3.69e+00\n",
      "Estimated with masking vs. true: 9.23e-04\n"
     ]
    }
   ],
   "source": [
    "true = Y_train_true[mask_train]\n",
    "corrupted = Y_train[mask_train]\n",
    "estimated = Y_train_hat[mask_train]\n",
    "estimated_mask = Y_train_hat_mask[mask_train]\n",
    "\n",
    "#\n",
    "\n",
    "print(\n",
    "    \"Examples of true, corrupted, estimated without masking and estimated with masking labels\"\n",
    ")\n",
    "for i in range(10):\n",
    "    print(\n",
    "        f\"True: {true[i]:+.2f}, corrup: {corrupted[i]:+.2f}, estim. w/o masking: {estimated[i]:+.2f}, estim. with masking: {estimated_mask[i]:+.2f}\"\n",
    "    )\n",
    "\n",
    "#\n",
    "\n",
    "print(\"\\nAverage quadratic error between true label and estimated labels\")\n",
    "print(f\"Estimated w/o masking vs. true: {metric(estimated, true):.2e}\")\n",
    "print(f\"Estimated with masking vs. true: {metric(estimated_mask, true):.2e}\")\n",
    "\n",
    "#\n",
    "\n",
    "print(\"\\nAverage quadratic error over all labels (corrupted or not)\")\n",
    "print(f\"Estimated w/o masking vs. true: {metric(Y_train_hat, Y_train_true):.2e}\")\n",
    "print(f\"Estimated with masking vs. true: {metric(Y_train_hat_mask, Y_train_true):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of true, corrupted, estimated without masking and estimated with masking labels\n",
      "True: +0.28, corrup: +4.28, estim. w/o masking: -0.43, estim. with masking: +0.30\n",
      "True: +3.49, corrup: +7.49, estim. w/o masking: -0.47, estim. with masking: +3.50\n",
      "True: +0.65, corrup: +4.65, estim. w/o masking: +0.20, estim. with masking: +0.65\n",
      "True: -0.02, corrup: +3.98, estim. w/o masking: -0.26, estim. with masking: +0.00\n",
      "True: +0.12, corrup: +4.12, estim. w/o masking: +0.14, estim. with masking: +0.12\n",
      "True: +1.36, corrup: +5.36, estim. w/o masking: +0.33, estim. with masking: +1.35\n",
      "True: +2.04, corrup: +6.04, estim. w/o masking: +0.45, estim. with masking: +2.05\n",
      "True: +0.00, corrup: +4.00, estim. w/o masking: +0.20, estim. with masking: +0.03\n",
      "True: +3.55, corrup: +7.55, estim. w/o masking: -0.51, estim. with masking: +3.55\n",
      "True: +3.49, corrup: +7.49, estim. w/o masking: -0.25, estim. with masking: +3.55\n",
      "\n",
      "Average quadratic error between true label and estimated labels\n",
      "Estimated w/o masking vs. true: 4.20e+00\n",
      "Estimated with masking vs. true: 3.35e-03\n",
      "\n",
      "Average quadratic error over all labels (corrupted or not)\n",
      "Estimated w/o masking vs. true: 3.43e+00\n",
      "Estimated with masking vs. true: 2.72e-03\n"
     ]
    }
   ],
   "source": [
    "true = Y_test_true[mask_test]\n",
    "corrupted = Y_test[mask_test]\n",
    "estimated = Y_test_hat[mask_test]\n",
    "estimated_mask = Y_test_hat_mask[mask_test]\n",
    "\n",
    "#\n",
    "\n",
    "print(\n",
    "    \"Examples of true, corrupted, estimated without masking and estimated with masking labels\"\n",
    ")\n",
    "for i in range(10):\n",
    "    print(\n",
    "        f\"True: {true[i]:+.2f}, corrup: {corrupted[i]:+.2f}, estim. w/o masking: {estimated[i]:+.2f}, estim. with masking: {estimated_mask[i]:+.2f}\"\n",
    "    )\n",
    "\n",
    "#\n",
    "\n",
    "print(\"\\nAverage quadratic error between true label and estimated labels\")\n",
    "print(f\"Estimated w/o masking vs. true: {metric(estimated, true):.2e}\")\n",
    "print(f\"Estimated with masking vs. true: {metric(estimated_mask, true):.2e}\")\n",
    "\n",
    "#\n",
    "\n",
    "print(\"\\nAverage quadratic error over all labels (corrupted or not)\")\n",
    "print(f\"Estimated w/o masking vs. true: {metric(Y_test_hat, Y_test_true):.2e}\")\n",
    "print(f\"Estimated with masking vs. true: {metric(Y_test_hat_mask, Y_test_true):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced example: how to detect anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use a robust loss function to detect outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_robust = net.copy()\n",
    "\n",
    "# Robust loss function (that is likely to ignore outliers)\n",
    "loss_robust = CauchyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer_robust = optim.Adam(net_robust.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initiated\n",
      "FullyConnected:\n",
      "\tlayers_sizes: [2, 50, 50, 3]\n",
      "\tactivation: ELU(alpha=1.0)\n",
      "\tbatch_norm: False\n",
      "\tinputs_names: None\n",
      "\toutputs_names: None\n",
      "\tinputs_transformer: None\n",
      "\toutputs_transformer: None\n",
      "\tdevice: cpu\n",
      "\tlast_restrictable: True\n",
      ": 2,853 learnable parameters (11.41 kB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 100/100 [00:36<00:00,  2.74it/s, train loss=0.16, val loss=0.135, train error=480567.91%, val error=50413.62%]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_params = LearningParameters(loss_robust, epochs, batch_size, optimizer_robust)\n",
    "\n",
    "results = learning_procedure(\n",
    "    net_robust,\n",
    "    (train_dataset, test_dataset),\n",
    "    learning_params,\n",
    "    val_frac=test_frac,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Compute outputs for both training and testing sets\n",
    "Y_train_hat_robust = net_robust(X_train)\n",
    "Y_test_hat_robust = net_robust(X_test)\n",
    "\n",
    "# Compute errors\n",
    "errors_train = metric(Y_train_hat_robust, Y_train_true, reduce=False)\n",
    "errors_test = metric(Y_test_hat_robust, Y_test_true, reduce=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection of outliers\n",
    "\n",
    "For the example, we will consider that we already know the fraction of anomalies in the data. If it wasn't the case, we could have use other methods to automatically or manually segment the samples in two categories (reliable and anomalies). Here, we just consider the first `100*p_damage` % of errors as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of anomalies well detected (train set): 0.2%\n",
      "Fraction of false alarms (train set): 4.8%\n",
      "\n",
      "Fraction of anomalies well detected (test set): 0.4%\n",
      "Fraction of false alarms (test set): 4.6%\n"
     ]
    }
   ],
   "source": [
    "mask_train_estimated = errors_train > np.quantile(errors_train, 1 - p_damage)\n",
    "mask_test_estimated = errors_test > np.quantile(errors_test, 1 - p_damage)\n",
    "\n",
    "#\n",
    "\n",
    "print(\n",
    "    f\"Fraction of anomalies well detected (train set): {100*np.mean(mask_train_estimated & mask_train):.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Fraction of false alarms (train set): {100*np.mean(mask_train_estimated & ~mask_train):.1f}%\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nFraction of anomalies well detected (test set): {100*np.mean(mask_test_estimated & mask_test):.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Fraction of false alarms (test set): {100*np.mean(mask_test_estimated & ~mask_test):.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask_train[:10])\n",
    "print(mask_train_estimated[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train a network with a masked non-robust loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_estimated_dataset = MaskDataset(\n",
    "    ~mask_train_estimated\n",
    ")  # Mask is inverted for training\n",
    "test_mask_estimated_dataset = MaskDataset(\n",
    "    ~mask_test_estimated\n",
    ")  # Mask is inverted for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_mask_2 = net.copy()\n",
    "\n",
    "# Non-robust masked loss function\n",
    "loss_mask_2 = MaskedMSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer_mask_2 = optim.Adam(net_mask_2.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initiated\n",
      "FullyConnected:\n",
      "\tlayers_sizes: [2, 50, 50, 3]\n",
      "\tactivation: ELU(alpha=1.0)\n",
      "\tbatch_norm: False\n",
      "\tinputs_names: None\n",
      "\toutputs_names: None\n",
      "\tinputs_transformer: None\n",
      "\toutputs_transformer: None\n",
      "\tdevice: cpu\n",
      "\tlast_restrictable: True\n",
      ": 2,853 learnable parameters (11.41 kB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 100/100 [00:49<00:00,  2.04it/s, train loss=1.17, val loss=0.712, train error=282423.75%, val error=27029.81%]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_params = LearningParameters(loss_mask_2, epochs, batch_size, optimizer_mask_2)\n",
    "\n",
    "results = learning_procedure(\n",
    "    net_mask_2,\n",
    "    (train_dataset, test_dataset),\n",
    "    learning_params,\n",
    "    mask_dataset=(train_mask_estimated_dataset, test_mask_estimated_dataset),\n",
    "    val_frac=test_frac,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have a network trained only on reliable labels which have been detected in a non-supervised way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnbma-aChir395-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
