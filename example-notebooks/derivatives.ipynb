{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks auto-differentiation using PyTorch 2.0\n",
    "\n",
    "Before running this notebook, you must run `training.ipynb` in order to generate the function and the network that will be loaded and derived in this notebook. Note that the tools that will be use are only available for `torch >= 2.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), \"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.func import jacrev, hessian, vmap\n",
    "\n",
    "from nnbma.networks import NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to differentiation with PyTorch\n",
    "\n",
    "We will use the following modules:\n",
    "* `jacrev`: compute the jacobian using reverse-mode autodiff\n",
    "* `jacfwd`: compute the jacobian using forward-mode autodiff\n",
    "* `hessian`: compute the jacobian using both reverse and forward-mode autodiff\n",
    "* `vmap`: vectorizing function used to compute the derivatives of batched inputs\n",
    "\n",
    "The computation of high order derivative can be done by composing several times `jacrev` and/or `jacfwd`. Note that `hessian` is just a convenience module defined as `hessian(f) = jacfwd(jacrev(f))`, but that the hessian computation can be done through other compositions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of the analytical function\n",
    "\n",
    "In the following cell, we will import the vectorial function $ f: \\left(\\begin{array}{c} t_1\\\\ t_2 \\end{array}\\right) \\longmapsto \\left(\\begin{array}{c} t_1+2t_2\\\\ t_1^2\\\\ t_1t_2^2 \\end{array}\\right) $.\n",
    "\n",
    "Please refer to `training.ipynb` for more details on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import F\n",
    "\n",
    "f = F()\n",
    "\n",
    "ranges = [(-2., 2.), (-1., 1.)] # Range of values of all inputs of f. Can be modified but must be consistent with the imported function.\n",
    "\n",
    "n_points = 100 # Number of points needed to plot a profile\n",
    "\n",
    "default_values = [0., 0.] # Default values of all inputs of f when plotting a profile. Can be modified but must be consistent with the imported function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.splitext(os.path.abspath(''))[0], \"out-training\")\n",
    "\n",
    "net = NeuralNetwork.load(\"network\", path)\n",
    "net.double().eval() # TODO\n",
    "print(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation of the analytical function\n",
    "\n",
    "In this part, we will compute the first and second order derivatives of the analytical function defined in `training.ipynb`. As the number of possible plots explodes when we differentiate a vectorial function several times, we will chose to represent only the evolution of a single output versus only one or two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of free input when plotting profiles, the others being restricted to their default value.\n",
    "input_to_plot = 1 # Must be between 1 and f.n_inputs\n",
    "\n",
    "# Index of free inputs when drawing bivariate plots, the others being restricted to their default value.\n",
    "inputs_to_plot = (1, 2) # Must be between 1 and f.n_inputs\n",
    "\n",
    "# Index of the output to plot.\n",
    "output_to_plot = 3 # Must be between 1 and f.n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_f = vmap(jacrev(f))\n",
    "hessian_f = vmap(hessian(f))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiles of first and second order derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(default_values) * np.ones((n_points, f.n_inputs), dtype=\"float\")\n",
    "x[:, input_to_plot-1] = np.linspace(*ranges[input_to_plot-1], n_points)\n",
    "print(\"x.shape:\", x.shape)\n",
    "\n",
    "dy = jacobian_f(torch.from_numpy(x)).detach().numpy()\n",
    "print(\"dy.shape:\", dy.shape)\n",
    "\n",
    "ddy = hessian_f(torch.from_numpy(x)).detach().numpy()\n",
    "print(\"ddy.shape:\", ddy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(f.n_inputs*6.4, 4.8))\n",
    "\n",
    "for i in range(f.n_inputs):\n",
    "\n",
    "    plt.subplot(f.n_inputs, f.n_outputs, i+1)\n",
    "\n",
    "    plt.plot(x[:, input_to_plot-1], dy[:, output_to_plot-1, i])\n",
    "\n",
    "    plt.xlabel(f\"$x_{input_to_plot}$\")\n",
    "    plt.ylabel(f\"$\\\\partial f_{output_to_plot} / \\\\partial x_{i+1}$\")\n",
    "    plt.title(f\"$\\\\partial f_{output_to_plot} / \\\\partial x_{i+1}$ vs $x_{input_to_plot}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(f.n_inputs*6.4, f.n_inputs*4.8))\n",
    "\n",
    "for i1 in range(f.n_inputs):\n",
    "\n",
    "    for i2 in range(f.n_inputs):\n",
    "\n",
    "        plt.subplot(f.n_inputs, f.n_inputs, i1*f.n_inputs+i2+1)\n",
    "\n",
    "        plt.plot(x[:, input_to_plot-1], ddy[:, output_to_plot-1, i1, i2])\n",
    "\n",
    "        plt.xlabel(f\"$x_{input_to_plot}$\")\n",
    "        plt.ylabel(f\"$\\\\partial^2 f_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$\")\n",
    "        plt.title(f\"$\\\\partial^2 f_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$ vs $x_{input_to_plot}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate plots of first and second order derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.dstack(np.meshgrid(\n",
    "    *[np.linspace(*ranges[i], n_points) if i+1 in inputs_to_plot else default_values[i] * np.ones(n_points) for i in range(f.n_inputs)]\n",
    "))\n",
    "print(\"X.shape:\", X.shape)\n",
    "\n",
    "dY = jacobian_f(torch.from_numpy(X.reshape(n_points**2, f.n_inputs))).detach().numpy().reshape(n_points, n_points, f.n_outputs, f.n_inputs)\n",
    "print(\"dY.shape:\", dY.shape)\n",
    "\n",
    "ddY = hessian_f(torch.from_numpy(X.reshape(n_points**2, f.n_inputs))).detach().numpy().reshape(n_points, n_points, f.n_outputs, f.n_inputs, f.n_inputs)\n",
    "print(\"ddY.shape:\", ddY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*f.n_inputs, 4.8))\n",
    "\n",
    "for i in range(f.n_inputs):\n",
    "    plt.subplot(1, f.n_inputs, i+1)\n",
    "    plt.imshow(\n",
    "        dY[:, :, output_to_plot-1, i], cmap=\"jet\", aspect=\"auto\", extent=[\n",
    "            ranges[inputs_to_plot[0]-1][0], ranges[inputs_to_plot[0]-1][1],\n",
    "            ranges[inputs_to_plot[1]-1][0], ranges[inputs_to_plot[1]-1][1],\n",
    "        ],\n",
    "    )\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xlabel(f\"$x_{inputs_to_plot[0]}$\")\n",
    "    plt.ylabel(f\"$x_{inputs_to_plot[1]}$\")\n",
    "    plt.title(f\"$\\\\partial f_{output_to_plot} / \\\\partial x_{i+1}$ vs $x_{inputs_to_plot[0]}$ and $x_{inputs_to_plot[1]}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*f.n_inputs, f.n_inputs*4.8))\n",
    "\n",
    "for i1 in range(f.n_inputs):\n",
    "\n",
    "    for i2 in range(f.n_inputs):\n",
    "\n",
    "        plt.subplot(f.n_inputs, f.n_inputs, i1*f.n_inputs+i2+1)\n",
    "        plt.imshow(\n",
    "            ddY[:, :, output_to_plot-1, i1, i2], cmap=\"jet\", aspect=\"auto\", extent=[\n",
    "                ranges[inputs_to_plot[0]-1][0], ranges[inputs_to_plot[0]-1][1],\n",
    "                ranges[inputs_to_plot[1]-1][0], ranges[inputs_to_plot[1]-1][1],\n",
    "            ],\n",
    "        )\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.xlabel(f\"$x_{inputs_to_plot[0]}$\")\n",
    "        plt.ylabel(f\"$x_{inputs_to_plot[1]}$\")\n",
    "        plt.title(f\"$\\\\partial^2 f_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$ vs $x_{inputs_to_plot[0]}$ and $x_{inputs_to_plot[1]}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation of the neural network\n",
    "\n",
    "We will now compute the first and second order derivatives of a neural network that has been trained to approximate the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_net = vmap(jacrev(net))\n",
    "hessian_net = vmap(hessian(net))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiles of first and second order derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(default_values) * np.ones((n_points, f.n_inputs), dtype=\"float\")\n",
    "x[:, input_to_plot-1] = np.linspace(*ranges[input_to_plot-1], n_points)\n",
    "print(\"x.shape:\", x.shape)\n",
    "\n",
    "dy_net = jacobian_net(torch.from_numpy(x)).detach().numpy()\n",
    "print(\"dy.shape:\", dy.shape)\n",
    "\n",
    "ddy_net = hessian_net(torch.from_numpy(x)).detach().numpy()\n",
    "print(\"ddy.shape:\", ddy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(f.n_inputs*6.4, 4.8))\n",
    "\n",
    "for i in range(f.n_inputs):\n",
    "\n",
    "    plt.subplot(f.n_inputs, f.n_outputs, i+1)\n",
    "\n",
    "    plt.plot(x[:, input_to_plot-1], dy_net[:, output_to_plot-1, i])\n",
    "\n",
    "    plt.xlabel(f\"$x_{input_to_plot}$\")\n",
    "    plt.ylabel(f\"$\\\\partial \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i+1}$\")\n",
    "    plt.title(f\"$\\\\partial \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i+1}$ vs $x_{input_to_plot}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(f.n_inputs*6.4, f.n_inputs*4.8))\n",
    "\n",
    "for i1 in range(f.n_inputs):\n",
    "\n",
    "    for i2 in range(f.n_inputs):\n",
    "\n",
    "        plt.subplot(f.n_inputs, f.n_inputs, i1*f.n_inputs+i2+1)\n",
    "\n",
    "        plt.plot(x[:, input_to_plot-1], ddy_net[:, output_to_plot-1, i1, i2])\n",
    "\n",
    "        plt.xlabel(f\"$x_{input_to_plot}$\")\n",
    "        plt.ylabel(f\"$\\\\partial^2 \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$\")\n",
    "        plt.title(f\"$\\\\partial^2 \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$ vs $x_{input_to_plot}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate plots of first and second order derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.dstack(np.meshgrid(\n",
    "    *[np.linspace(*ranges[i], n_points) if i+1 in inputs_to_plot else default_values[i] * np.ones(n_points) for i in range(f.n_inputs)]\n",
    "))\n",
    "print(\"X.shape:\", X.shape)\n",
    "\n",
    "dY_net = jacobian_net(torch.from_numpy(X.reshape(n_points**2, f.n_inputs))).detach().numpy().reshape(n_points, n_points, f.n_outputs, f.n_inputs)\n",
    "print(\"dY.shape:\", dY.shape)\n",
    "\n",
    "ddY_net = hessian_net(torch.from_numpy(X.reshape(n_points**2, f.n_inputs))).detach().numpy().reshape(n_points, n_points, f.n_outputs, f.n_inputs, f.n_inputs)\n",
    "print(\"ddY.shape:\", ddY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*f.n_inputs, 4.8))\n",
    "\n",
    "for i in range(f.n_inputs):\n",
    "    plt.subplot(1, f.n_inputs, i+1)\n",
    "    plt.imshow(\n",
    "        dY_net[:, :, output_to_plot-1, i], cmap=\"jet\", aspect=\"auto\", extent=[\n",
    "            ranges[inputs_to_plot[0]-1][0], ranges[inputs_to_plot[0]-1][1],\n",
    "            ranges[inputs_to_plot[1]-1][0], ranges[inputs_to_plot[1]-1][1],\n",
    "        ],\n",
    "    )\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xlabel(f\"$x_{inputs_to_plot[0]}$\")\n",
    "    plt.ylabel(f\"$x_{inputs_to_plot[1]}$\")\n",
    "    plt.title(f\"$\\\\partial \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i+1}$ vs $x_{inputs_to_plot[0]}$ and $x_{inputs_to_plot[1]}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*f.n_inputs, f.n_inputs*4.8))\n",
    "\n",
    "for i1 in range(f.n_inputs):\n",
    "\n",
    "    for i2 in range(f.n_inputs):\n",
    "\n",
    "        plt.subplot(f.n_inputs, f.n_inputs, i1*f.n_inputs+i2+1)\n",
    "        plt.imshow(\n",
    "            ddY_net[:, :, output_to_plot-1, i1, i2], cmap=\"jet\", aspect=\"auto\", extent=[\n",
    "                ranges[inputs_to_plot[0]-1][0], ranges[inputs_to_plot[0]-1][1],\n",
    "                ranges[inputs_to_plot[1]-1][0], ranges[inputs_to_plot[1]-1][1],\n",
    "            ],\n",
    "        )\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.xlabel(f\"$x_{inputs_to_plot[0]}$\")\n",
    "        plt.ylabel(f\"$x_{inputs_to_plot[1]}$\")\n",
    "        plt.title(f\"$\\\\partial^2 \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$ vs $x_{inputs_to_plot[0]}$ and $x_{inputs_to_plot[1]}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors of approximated derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative = True\n",
    "eps = 1e-2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiles of first and second order derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dy = (dy_net - dy) / (np.abs(dy)+eps) if relative else dy_net - dy\n",
    "print(\"error_dy.shape:\", error_dy.shape)\n",
    "\n",
    "error_ddy = (ddy_net - ddy) / (np.abs(ddy)+eps) if relative else ddy_net - ddy\n",
    "print(\"error_ddy.shape:\", error_ddy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(f.n_inputs*6.4, 4.8))\n",
    "\n",
    "for i in range(f.n_inputs):\n",
    "        \n",
    "    vmax = np.abs(error_dy[:, output_to_plot-1, i]).max()\n",
    "\n",
    "    plt.subplot(f.n_inputs, f.n_outputs, i+1)\n",
    "\n",
    "    plt.plot(x[:, input_to_plot-1], error_dy[:, output_to_plot-1, i])\n",
    "    plt.ylim([-1.1*vmax, 1.1*vmax])\n",
    "\n",
    "    plt.xlabel(f\"$x_{input_to_plot}$\")\n",
    "    plt.ylabel(f\"Error of $\\\\partial \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i+1}$\")\n",
    "    plt.title(f\"Error of $\\\\partial \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i+1}$ vs $x_{input_to_plot}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(f.n_inputs*6.4, f.n_inputs*4.8))\n",
    "\n",
    "for i1 in range(f.n_inputs):\n",
    "\n",
    "    for i2 in range(f.n_inputs):\n",
    "\n",
    "        vmax = np.abs(error_ddy[:, output_to_plot-1, i1, i2]).max()\n",
    "\n",
    "        plt.subplot(f.n_inputs, f.n_inputs, i1*f.n_inputs+i2+1)\n",
    "\n",
    "        plt.plot(x[:, input_to_plot-1], error_ddy[:, output_to_plot-1, i1, i2])\n",
    "        plt.ylim([-1.1*vmax, 1.1*vmax])\n",
    "\n",
    "        plt.xlabel(f\"$x_{input_to_plot}$\")\n",
    "        plt.ylabel(f\"Error of $\\\\partial^2 \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$\")\n",
    "        plt.title(f\"Error of $\\\\partial^2 \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$ vs $x_{input_to_plot}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate plots of first and second order derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_dY = (dY_net - dY) / (np.abs(dY)+eps) if relative else dY_net - dY\n",
    "print(\"Error_dY.shape:\", dY.shape)\n",
    "\n",
    "Error_ddY = (ddY_net - ddY) / (np.abs(ddY)+eps) if relative else ddY_net - ddY\n",
    "print(\"Error_ddY.shape:\", ddY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*f.n_inputs, 4.8))\n",
    "\n",
    "for i in range(f.n_inputs):\n",
    "            \n",
    "    vmax = np.abs(Error_dY[:, :, output_to_plot-1, i]).max()\n",
    "\n",
    "    plt.subplot(1, f.n_inputs, i+1)\n",
    "    plt.imshow(\n",
    "        Error_dY[:, :, output_to_plot-1, i], cmap=\"seismic\", aspect=\"auto\", extent=[\n",
    "            ranges[inputs_to_plot[0]-1][0], ranges[inputs_to_plot[0]-1][1],\n",
    "            ranges[inputs_to_plot[1]-1][0], ranges[inputs_to_plot[1]-1][1],\n",
    "        ], vmin=-vmax, vmax=vmax,\n",
    "    )\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xlabel(f\"$x_{inputs_to_plot[0]}$\")\n",
    "    plt.ylabel(f\"$x_{inputs_to_plot[1]}$\")\n",
    "    plt.title(f\"Error of $\\\\partial \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i+1}$ vs $x_{inputs_to_plot[0]}$ and $x_{inputs_to_plot[1]}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*f.n_inputs, f.n_inputs*4.8))\n",
    "\n",
    "for i1 in range(f.n_inputs):\n",
    "\n",
    "    for i2 in range(f.n_inputs):\n",
    "\n",
    "        vmax = np.abs(Error_ddY[:, :, output_to_plot-1, i1, i2]).max()\n",
    "\n",
    "        plt.subplot(f.n_inputs, f.n_inputs, i1*f.n_inputs+i2+1)\n",
    "        plt.imshow(\n",
    "            Error_ddY[:, :, output_to_plot-1, i1, i2], cmap=\"seismic\", aspect=\"auto\", extent=[\n",
    "                ranges[inputs_to_plot[0]-1][0], ranges[inputs_to_plot[0]-1][1],\n",
    "                ranges[inputs_to_plot[1]-1][0], ranges[inputs_to_plot[1]-1][1],\n",
    "            ], vmin=-vmax, vmax=vmax,\n",
    "        )\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.xlabel(f\"$x_{inputs_to_plot[0]}$\")\n",
    "        plt.ylabel(f\"$x_{inputs_to_plot[1]}$\")\n",
    "        plt.title(f\"Error of $\\\\partial^2 \\\\hat{{f}}_{output_to_plot} / \\\\partial x_{i1+1} \\\\partial x_{i2+1}$ vs $x_{inputs_to_plot[0]}$ and $x_{inputs_to_plot[1]}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
